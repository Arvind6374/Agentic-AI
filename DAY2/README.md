# Agentic AI â€“ Day 2

A continuation into understanding the LLM ecosystem, choosing the right model, handling PII safely, and learning prompt engineering.
This module focuses on LLM types, privacy concerns, cost/latency, batch vs real-time processing, and hands-on work with tools like HuggingFace and Ollama.

---

## ğŸš€ Day 2 Overview

### âœ” Types of LLMs

#### ğŸ”’ Closed-Source Models (API-Based)

Examples: GPT-4, Gemini

* Highly powerful
* Require API keys
* Per-token cost
* Data privacy concerns

#### ğŸŸ© Open-Source Models (Local)

Examples: Llama 3, Mistral, Gamma

* Free to run locally
* Full data control
* Ideal for sensitive data
* Need sufficient CPU/GPU hardware

---

## ğŸ” Understanding PII (Personal Identifiable Information)

PII includes any information that identifies a person.
Examples:

* Aadhaar number
* Biometrics
* Phone number
* Email / address
* Medical data

â¡ When PII is present â†’ **use local models** or **redact PII before sending to APIs**.

---

## ğŸ•’ Batch vs Real-Time Processing

### ğŸ“¦ Batch Processing

* Works on historical data
* Not time-critical
* Example: Summarizing yesterdayâ€™s 10,000 news articles

### âš¡ Real-Time Processing

* Instant responses required
* Example: Travel chatbot
* Best handled using fast API models (Gemini / GPT)

---

## ğŸ’¸ Cost & Latency

* Closed-source models â†’ token-based pricing
* Open-source models â†’ free, hardware dependent
* Larger models â†’ slower + require more memory

---

## âœï¸ Prompt Engineering (ROLES Method)

A structured method for creating effective prompts:

* **R â€“ Role:** Define AIâ€™s behavior
* **O â€“ Objective:** Task to be performed
* **L â€“ Limitations:** Rules, constraints, word limits
* **E â€“ Examples:** Few-shot examples to guide behavior
* **S â€“ Style:** Output format (Markdown, JSON, table, etc.)

---

## ğŸ§  Advanced Prompt Techniques

### ğŸ§© Chain of Thought

Ask the model to **think step-by-step** for better reasoning.

### ğŸ” Self-Consistency

Model generates multiple reasoning paths â†’ best one selected.

---

## ğŸ›  Hands-On Setup

### ğŸ¤– Running Local Models with Ollama

1. Install Ollama: [https://ollama.com](https://ollama.com)
2. Run a model:

   ```bash
   ollama run llama3 "hi"
   ```

Recommended lightweight models:

* Gamma 3 (1B)
* Llama 3 small variants

---

### ğŸ“˜ Exploring HuggingFace

Reviewed:

* Model configs
* Tokenizer information
* Sample usage code
* Model sizes and capabilities

---

## ğŸ¯ Use-Case Scenarios Discussed

* **Legal Contracts (Sensitive Data)** â†’ Use local open-source models
* **Travel Chatbot (Public Use)** â†’ Use Gemini / GPT APIs
* **Batch News Summaries (Large Volume)** â†’ Use lightweight open-source models

---

## ğŸ§° Tools Used Today

* PyCharm
* Google Colab
* HuggingFace
* Ollama

---
