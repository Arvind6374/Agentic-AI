{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dOwE4pgwm8VH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39cea72c-09c0-4bc0-a76a-d0219cd6dab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.4/132.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.19.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.0 which is incompatible.\n",
            "google-adk 1.19.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q google-generativeai chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import re\n",
        "from typing import List, Dict, Tuple\n",
        "import google.generativeai as genai\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "\n",
        "# ==================== CONFIGURATION ====================\n",
        "\n",
        "class RAGConfig:\n",
        "    \"\"\"Configuration for RAG system\"\"\"\n",
        "    GEMINI_MODEL = \"gemini-2.5-flash-lite\"\n",
        "    EMBEDDING_MODEL = \"models/text-embedding-004\"\n",
        "    CHUNK_SIZE = 500\n",
        "    CHUNK_OVERLAP = 50 # Chunk1 and Chunk 2 will have 50 char similar\n",
        "    TOP_K_RESULTS = 3\n",
        "    COLLECTION_NAME = \"rag_documents\"\n",
        "\n",
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get(\"DAY1\")\n",
        "# Set your API key  # Replace with your actual API key\n",
        "genai.configure(api_key=GEMINI_API_KEY)"
      ],
      "metadata": {
        "id": "4H6q4mUV9hGS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CUSTOM TEXT LOADER"
      ],
      "metadata": {
        "id": "2umaQFrqAfbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "class CustomTextLoader:\n",
        "    \"\"\"Custom loader for reading .txt files\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def load_file(file_path: str) -> str:\n",
        "        \"\"\"Load text from a single .txt file\"\"\"\n",
        "        if not file_path.endswith('.txt'):\n",
        "            raise ValueError(\"Only .txt files are supported\")\n",
        "\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        return content\n",
        "\n",
        "    @staticmethod\n",
        "    def load_directory(directory_path: str) -> List[Dict[str, str]]:\n",
        "        \"\"\"Load all .txt files from a directory\"\"\"\n",
        "        documents = []\n",
        "\n",
        "        for filename in os.listdir(directory_path):\n",
        "            if filename.endswith('.txt'):\n",
        "                file_path = os.path.join(directory_path, filename)\n",
        "                content = CustomTextLoader.load_file(file_path)\n",
        "                documents.append({\n",
        "                    'content': content,\n",
        "                    'source': filename,\n",
        "                    'path': file_path\n",
        "                })\n",
        "\n",
        "        return documents\n"
      ],
      "metadata": {
        "id": "DP6m43PqAehk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CUSTOM TEXT SPLITTER"
      ],
      "metadata": {
        "id": "S8mW4Qg7Ap_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CustomTextSplitter:\n",
        "    \"\"\"Custom text splitter with overlap support\"\"\"\n",
        "\n",
        "    def __init__(self, chunk_size: int = 500, chunk_overlap: int = 50):\n",
        "        self.chunk_size = chunk_size\n",
        "        self.chunk_overlap = chunk_overlap\n",
        "\n",
        "    def split_text(self, text: str) -> List[str]:\n",
        "        \"\"\"Split text into chunks with overlap\"\"\"\n",
        "        # Clean the text\n",
        "        text = self._clean_text(text)\n",
        "\n",
        "        # Split by sentences first for better semantic boundaries\n",
        "        sentences = self._split_into_sentences(text)\n",
        "\n",
        "        chunks = []\n",
        "        current_chunk = []\n",
        "        current_length = 0\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence_length = len(sentence)\n",
        "\n",
        "            if current_length + sentence_length > self.chunk_size and current_chunk:\n",
        "                # Save current chunk\n",
        "                chunks.append(' '.join(current_chunk))\n",
        "\n",
        "                # Create overlap by keeping last few sentences\n",
        "                overlap_text = ' '.join(current_chunk)\n",
        "                overlap_sentences = []\n",
        "                overlap_length = 0\n",
        "\n",
        "                for s in reversed(current_chunk):\n",
        "                    if overlap_length + len(s) <= self.chunk_overlap:\n",
        "                        overlap_sentences.insert(0, s)\n",
        "                        overlap_length += len(s)\n",
        "                    else:\n",
        "                        break\n",
        "\n",
        "                current_chunk = overlap_sentences\n",
        "                current_length = overlap_length\n",
        "\n",
        "            current_chunk.append(sentence)\n",
        "            current_length += sentence_length\n",
        "\n",
        "        # Add the last chunk\n",
        "        if current_chunk:\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    @staticmethod\n",
        "    def _clean_text(text: str) -> str:\n",
        "        \"\"\"Clean and normalize text\"\"\"\n",
        "        # Remove extra whitespace\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        # Remove special characters but keep punctuation\n",
        "        text = re.sub(r'[^\\w\\s.,!?;:\\-\\'\\\"()]', '', text)\n",
        "        return text.strip()\n",
        "\n",
        "    @staticmethod\n",
        "    def _split_into_sentences(text: str) -> List[str]:\n",
        "        \"\"\"Split text into sentences\"\"\"\n",
        "        # Simple sentence splitter\n",
        "        sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
        "        return [s.strip() for s in sentences if s.strip()]"
      ],
      "metadata": {
        "id": "uvhbTG1kAntB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EmbeddingManager"
      ],
      "metadata": {
        "id": "iU8M6N0IAzeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class EmbeddingManager:\n",
        "    \"\"\"Manage embeddings using Gemini's embedding model\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = RAGConfig.EMBEDDING_MODEL):\n",
        "        self.model_name = model_name\n",
        "\n",
        "    def embed_text(self, text: str) -> List[float]:\n",
        "        \"\"\"Generate embedding for a single text\"\"\"\n",
        "        result = genai.embed_content(\n",
        "            model=self.model_name,\n",
        "            content=text,\n",
        "            task_type=\"retrieval_document\"\n",
        "        )\n",
        "        return result['embedding']\n",
        "\n",
        "    def embed_query(self, query: str) -> List[float]:\n",
        "        \"\"\"Generate embedding for a query\"\"\"\n",
        "        result = genai.embed_content(\n",
        "            model=self.model_name,\n",
        "            content=query,\n",
        "            task_type=\"retrieval_query\"\n",
        "        )\n",
        "        return result['embedding']\n",
        "\n",
        "    def embed_batch(self, texts: List[str]) -> List[List[float]]:\n",
        "        \"\"\"Generate embeddings for multiple texts\"\"\"\n",
        "        embeddings = []\n",
        "        for text in texts:\n",
        "            embedding = self.embed_text(text)\n",
        "            embeddings.append(embedding)\n",
        "        return embeddings"
      ],
      "metadata": {
        "id": "uP9sN_q8AxSI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VECTOR STORE"
      ],
      "metadata": {
        "id": "sZz7TuZYB3_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class VectorStore:\n",
        "    \"\"\"ChromaDB vector store manager\"\"\"\n",
        "\n",
        "    def __init__(self, collection_name: str = RAGConfig.COLLECTION_NAME):\n",
        "        self.client = chromadb.Client(Settings(\n",
        "            anonymized_telemetry=False,\n",
        "            allow_reset=True\n",
        "        ))\n",
        "        self.collection_name = collection_name\n",
        "        self.collection = None\n",
        "        self.embedding_manager = EmbeddingManager()\n",
        "\n",
        "    def create_collection(self, reset: bool = False):\n",
        "        \"\"\"Create or get collection\"\"\"\n",
        "        if reset:\n",
        "            try:\n",
        "                self.client.delete_collection(name=self.collection_name)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        self.collection = self.client.get_or_create_collection(\n",
        "            name=self.collection_name,\n",
        "            metadata={\"description\": \"RAG document embeddings\"}\n",
        "        )\n",
        "\n",
        "    def add_documents(self, chunks: List[str], metadatas: List[Dict]):\n",
        "        \"\"\"Add document chunks to the vector store\"\"\"\n",
        "        if not self.collection:\n",
        "            self.create_collection()\n",
        "\n",
        "        print(f\"Generating embeddings for {len(chunks)} chunks...\")\n",
        "        embeddings = self.embedding_manager.embed_batch(chunks)\n",
        "\n",
        "        # Generate IDs\n",
        "        ids = [f\"chunk_{i}\" for i in range(len(chunks))]\n",
        "\n",
        "        print(f\"Adding {len(chunks)} chunks to ChromaDB...\")\n",
        "        self.collection.add(\n",
        "            embeddings=embeddings,\n",
        "            documents=chunks,\n",
        "            metadatas=metadatas,\n",
        "            ids=ids\n",
        "        )\n",
        "        print(\"âœ“ Documents added successfully!\")\n",
        "\n",
        "    def query(self, query_text: str, top_k: int = RAGConfig.TOP_K_RESULTS) -> Dict:\n",
        "        \"\"\"Query the vector store\"\"\"\n",
        "        if not self.collection:\n",
        "            raise ValueError(\"Collection not initialized\")\n",
        "\n",
        "        # Generate query embedding\n",
        "        query_embedding = self.embedding_manager.embed_query(query_text)\n",
        "\n",
        "        # Search\n",
        "        results = self.collection.query(\n",
        "            query_embeddings=[query_embedding],\n",
        "            n_results=top_k\n",
        "        )\n",
        "\n",
        "        return results"
      ],
      "metadata": {
        "id": "TtI-hyx_-g67"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG SYSTEM"
      ],
      "metadata": {
        "id": "3WXosk-wFjan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class RAGSystem:\n",
        "    \"\"\"Complete RAG system\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.vector_store = VectorStore()\n",
        "        self.text_splitter = CustomTextSplitter(\n",
        "            chunk_size=RAGConfig.CHUNK_SIZE,\n",
        "            chunk_overlap=RAGConfig.CHUNK_OVERLAP\n",
        "        )\n",
        "        self.model = genai.GenerativeModel(RAGConfig.GEMINI_MODEL)\n",
        "\n",
        "    def ingest_documents(self, file_path: str = None, directory_path: str = None, reset: bool = True):\n",
        "        \"\"\"Ingest documents from file or directory\"\"\"\n",
        "        loader = CustomTextLoader()\n",
        "\n",
        "        # Load documents\n",
        "        if file_path:\n",
        "            content = loader.load_file(file_path)\n",
        "            documents = [{'content': content, 'source': os.path.basename(file_path)}]\n",
        "        elif directory_path:\n",
        "            documents = loader.load_directory(directory_path)\n",
        "        else:\n",
        "            raise ValueError(\"Either file_path or directory_path must be provided\")\n",
        "\n",
        "        print(f\"Loaded {len(documents)} document(s)\")\n",
        "\n",
        "        # Split documents into chunks\n",
        "        all_chunks = []\n",
        "        all_metadata = []\n",
        "\n",
        "        for doc in documents:\n",
        "            chunks = self.text_splitter.split_text(doc['content'])\n",
        "            print(f\"Split {doc['source']} into {len(chunks)} chunks\")\n",
        "\n",
        "            for i, chunk in enumerate(chunks):\n",
        "                all_chunks.append(chunk)\n",
        "                all_metadata.append({\n",
        "                    'source': doc['source'],\n",
        "                    'chunk_id': i,\n",
        "                    'total_chunks': len(chunks)\n",
        "                })\n",
        "\n",
        "        # Create collection and add documents\n",
        "        self.vector_store.create_collection(reset=reset)\n",
        "        self.vector_store.add_documents(all_chunks, all_metadata)\n",
        "\n",
        "        print(f\"\\nâœ“ Ingestion complete! Total chunks: {len(all_chunks)}\")\n",
        "\n",
        "    def query(self, question: str, top_k: int = RAGConfig.TOP_K_RESULTS) -> Tuple[str, List[Dict]]:\n",
        "        \"\"\"Query the RAG system\"\"\"\n",
        "        # Retrieve relevant documents\n",
        "        results = self.vector_store.query(question, top_k=top_k)\n",
        "\n",
        "        # Extract context\n",
        "        contexts = results['documents'][0]\n",
        "        metadatas = results['metadatas'][0]\n",
        "\n",
        "        # Build context string\n",
        "        context_str = \"\\n\\n\".join([\n",
        "            f\"[Source: {meta['source']}, Chunk {meta['chunk_id']+1}/{meta['total_chunks']}]\\n{doc}\"\n",
        "            for doc, meta in zip(contexts, metadatas)\n",
        "        ])\n",
        "\n",
        "        # Create prompt\n",
        "        prompt = f\"\"\"Answer the question based on the context provided.\n",
        "        If the answer cannot be found in the context,\n",
        "        say \"I cannot answer this based on the provided context.\"\n",
        "\n",
        "Context:\n",
        "{context_str}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "        # Generate response\n",
        "        response = self.model.generate_content(prompt)\n",
        "\n",
        "        # Prepare source information\n",
        "        sources = [\n",
        "            {\n",
        "                'source': meta['source'],\n",
        "                'chunk_id': meta['chunk_id'],\n",
        "                'text': doc[:200] + \"...\"\n",
        "            }\n",
        "            for doc, meta in zip(contexts, metadatas)\n",
        "        ]\n",
        "\n",
        "        return response.text, sources\n"
      ],
      "metadata": {
        "id": "TqpBoSi0FhMH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INTERACTIVE MODE"
      ],
      "metadata": {
        "id": "IOD8dWqYFSEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def interactive_mode():\n",
        "    \"\"\"Run RAG system in Interactive Mode\"\"\"\n",
        "    print(\" Starting RAG System in Interactive Mode...\")\n",
        "    rag = RAGSystem()\n",
        "\n",
        "    # Define default sample file name\n",
        "    DEFAULT_SAMPLE_FILE = 'sample_ai.txt'\n",
        "\n",
        "    # Always create the sample file first, in case the user wants to use it or makes a mistake\n",
        "    print(\"Creating/updating a sample document for default use...\")\n",
        "    with open(DEFAULT_SAMPLE_FILE, 'w', encoding='utf-8') as f:\n",
        "        f.write(\"\"\"\n",
        "        Artificial Intelligence (AI) is transforming the world. Machine learning, a subset of AI,\n",
        "        enables computers to learn from data without explicit programming. Deep learning uses neural\n",
        "        networks with multiple layers to process complex patterns.\n",
        "\n",
        "        Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\n",
        "        It powers applications like chatbots, translation services, and sentiment analysis.\n",
        "\n",
        "        Computer vision is another important AI field that enables machines to interpret visual information.\n",
        "        It's used in facial recognition, autonomous vehicles, and medical imaging.\n",
        "\n",
        "        The future of AI includes advancements in quantum computing, edge AI, and explainable AI systems.\n",
        "        \"\"\")\n",
        "\n",
        "    # Get file path from user\n",
        "    user_file_path = input(f\"\\nEnter path to .txt file (or press Enter to use '{DEFAULT_SAMPLE_FILE}'): \").strip()\n",
        "\n",
        "    file_to_ingest = \"\"\n",
        "    if not user_file_path:\n",
        "        print(f\"Using default sample document: {DEFAULT_SAMPLE_FILE}\")\n",
        "        file_to_ingest = DEFAULT_SAMPLE_FILE\n",
        "    else:\n",
        "        # Check if the user-provided file exists\n",
        "        if os.path.exists(user_file_path):\n",
        "            file_to_ingest = user_file_path\n",
        "            print(f\"Using user-provided file: {file_to_ingest}\")\n",
        "        else:\n",
        "            print(f\"File not found at '{user_file_path}'. Using default sample document: {DEFAULT_SAMPLE_FILE}\")\n",
        "            file_to_ingest = DEFAULT_SAMPLE_FILE\n",
        "\n",
        "\n",
        "    # Ingest documents\n",
        "    rag.ingest_documents(file_path=file_to_ingest)\n",
        "\n",
        "    # Interactive query loop\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\" RAG System Ready! Type 'quit' or 'exit' to stop.\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    while True:\n",
        "        question = input(\"\\nâ“ Your question: \").strip()\n",
        "\n",
        "        if question.lower() in ['quit', 'exit', 'q']:\n",
        "            print(\" Goodbye!\")\n",
        "            break\n",
        "\n",
        "        if not question:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            answer, sources = rag.query(question)\n",
        "            print(f\"\\n Answer:\\n{answer}\\n\")\n",
        "            print(\"ğŸ“„ Sources:\")\n",
        "            for i, source in enumerate(sources, 1):\n",
        "                print(f\"  {i}. {source['source']} (Chunk {source['chunk_id']+1})\")\n",
        "        except Exception as e:\n",
        "            print(f\" Error: {str(e)}\")\n",
        "\n",
        "# Uncomment to run interactive mode:\n",
        "interactive_mode()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "j__HnDYlB6vx",
        "outputId": "193f62e3-4c69-434b-f56c-a9f5d5b941d8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Starting RAG System in Interactive Mode...\n",
            "Creating/updating a sample document for default use...\n",
            "\n",
            "Enter path to .txt file (or press Enter to use 'sample_ai.txt'): sample_ai.txt\n",
            "Using user-provided file: sample_ai.txt\n",
            "Loaded 1 document(s)\n",
            "Split sample_ai.txt into 2 chunks\n",
            "Generating embeddings for 2 chunks...\n",
            "Adding 2 chunks to ChromaDB...\n",
            "âœ“ Documents added successfully!\n",
            "\n",
            "âœ“ Ingestion complete! Total chunks: 2\n",
            "\n",
            "======================================================================\n",
            " RAG System Ready! Type 'quit' or 'exit' to stop.\n",
            "======================================================================\n",
            "\n",
            "â“ Your question: What is RAG system?\n",
            "\n",
            " Answer:\n",
            "I cannot answer this based on the provided context.\n",
            "\n",
            "ğŸ“„ Sources:\n",
            "  1. sample_ai.txt (Chunk 1)\n",
            "  2. sample_ai.txt (Chunk 2)\n",
            "\n",
            "â“ Your question: quit\n",
            " Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIlBXPKVGCi7",
        "outputId": "beccb968-123a-46ef-d13c-e0f97182158c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXAMPLE USAGE"
      ],
      "metadata": {
        "id": "F72uo3a8G6Hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Example usage of the RAG system\"\"\"\n",
        "\n",
        "    # Initialize RAG system\n",
        "    print(\"ğŸš€ Initializing RAG System...\")\n",
        "    rag = RAGSystem()\n",
        "\n",
        "    # Example 1: Create a sample text file\n",
        "    print(\"\\nğŸ“ Creating sample document...\")\n",
        "    sample_text = \"\"\"\n",
        "    Artificial Intelligence (AI) is transforming the world. Machine learning, a subset of AI,\n",
        "    enables computers to learn from data without explicit programming. Deep learning uses neural\n",
        "    networks with multiple layers to process complex patterns.\n",
        "\n",
        "    Natural Language Processing (NLP) is a branch of AI that helps computers understand human language.\n",
        "    It powers applications like chatbots, translation services, and sentiment analysis.\n",
        "\n",
        "    Computer vision is another important AI field that enables machines to interpret visual information.\n",
        "    It's used in facial recognition, autonomous vehicles, and medical imaging.\n",
        "\n",
        "    The future of AI includes advancements in quantum computing, edge AI, and explainable AI systems.\n",
        "    \"\"\"\n",
        "\n",
        "    with open('sample_ai.txt', 'w', encoding='utf-8') as f:\n",
        "        f.write(sample_text)\n",
        "\n",
        "    # Example 2: Ingest the document\n",
        "    print(\"\\nğŸ“š Ingesting documents...\")\n",
        "    rag.ingest_documents(file_path='sample_ai.txt')\n",
        "\n",
        "    # Example 3: Query the system\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ğŸ’¬ RAG SYSTEM READY - Ask questions!\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    questions = [\n",
        "        \"What is machine learning?\",\n",
        "        \"What are the applications of NLP?\",\n",
        "        \"What is the future of AI?\"\n",
        "    ]\n",
        "\n",
        "    for question in questions:\n",
        "        print(f\"\\nâ“ Question: {question}\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        answer, sources = rag.query(question)\n",
        "\n",
        "        print(f\"ğŸ¤– Answer:\\n{answer}\\n\")\n",
        "        print(\"ğŸ“„ Sources:\")\n",
        "        for i, source in enumerate(sources, 1):\n",
        "            print(f\"  {i}. {source['source']} (Chunk {source['chunk_id']+1})\")\n",
        "            print(f\"     Preview: {source['text']}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "eLPPWePbG1SB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "outputId": "79a2520b-7ae4-4cca-e70e-512fcc28a2ad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Initializing RAG System...\n",
            "\n",
            "ğŸ“ Creating sample document...\n",
            "\n",
            "ğŸ“š Ingesting documents...\n",
            "Loaded 1 document(s)\n",
            "Split sample_ai.txt into 2 chunks\n",
            "Generating embeddings for 2 chunks...\n",
            "Adding 2 chunks to ChromaDB...\n",
            "âœ“ Documents added successfully!\n",
            "\n",
            "âœ“ Ingestion complete! Total chunks: 2\n",
            "\n",
            "======================================================================\n",
            "ğŸ’¬ RAG SYSTEM READY - Ask questions!\n",
            "======================================================================\n",
            "\n",
            "â“ Question: What is machine learning?\n",
            "----------------------------------------------------------------------\n",
            "ğŸ¤– Answer:\n",
            "Machine learning is a subset of AI that enables computers to learn from data without explicit programming.\n",
            "\n",
            "ğŸ“„ Sources:\n",
            "  1. sample_ai.txt (Chunk 1)\n",
            "     Preview: Artificial Intelligence (AI) is transforming the world. Machine learning, a subset of AI, enables computers to learn from data without explicit programming. Deep learning uses neural networks with mul...\n",
            "\n",
            "  2. sample_ai.txt (Chunk 2)\n",
            "     Preview: Computer vision is another important AI field that enables machines to interpret visual information. It's used in facial recognition, autonomous vehicles, and medical imaging. The future of AI include...\n",
            "\n",
            "\n",
            "â“ Question: What are the applications of NLP?\n",
            "----------------------------------------------------------------------\n",
            "ğŸ¤– Answer:\n",
            "NLP powers applications like chatbots, translation services, and sentiment analysis.\n",
            "\n",
            "ğŸ“„ Sources:\n",
            "  1. sample_ai.txt (Chunk 1)\n",
            "     Preview: Artificial Intelligence (AI) is transforming the world. Machine learning, a subset of AI, enables computers to learn from data without explicit programming. Deep learning uses neural networks with mul...\n",
            "\n",
            "  2. sample_ai.txt (Chunk 2)\n",
            "     Preview: Computer vision is another important AI field that enables machines to interpret visual information. It's used in facial recognition, autonomous vehicles, and medical imaging. The future of AI include...\n",
            "\n",
            "\n",
            "â“ Question: What is the future of AI?\n",
            "----------------------------------------------------------------------\n",
            "ğŸ¤– Answer:\n",
            "The future of AI includes advancements in quantum computing, edge AI, and explainable AI systems.\n",
            "\n",
            "ğŸ“„ Sources:\n",
            "  1. sample_ai.txt (Chunk 2)\n",
            "     Preview: Computer vision is another important AI field that enables machines to interpret visual information. It's used in facial recognition, autonomous vehicles, and medical imaging. The future of AI include...\n",
            "\n",
            "  2. sample_ai.txt (Chunk 1)\n",
            "     Preview: Artificial Intelligence (AI) is transforming the world. Machine learning, a subset of AI, enables computers to learn from data without explicit programming. Deep learning uses neural networks with mul...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jbi2mAZxbE6w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}